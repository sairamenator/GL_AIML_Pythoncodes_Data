{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R8_Internal_Lab_Questions_17MAR2019_Sairam.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"text","id":"NFfDTfhlaEI_"},"cell_type":"markdown","source":["# Transfer Learning MNIST"]},{"metadata":{"colab_type":"text","id":"rNwbqCFRaEJC"},"cell_type":"markdown","source":["* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n","* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."]},{"metadata":{"colab_type":"text","id":"YUB1uDW_8XIy"},"cell_type":"markdown","source":["## 1. Import necessary libraries for the model"]},{"metadata":{"colab_type":"code","id":"Rsj4t5HTaEJE","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a7dd0ec0-f64e-4f07-bc65-0ca61e49641e","executionInfo":{"status":"ok","timestamp":1552822409084,"user_tz":-330,"elapsed":1546,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["#Importing important modules\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","import tensorflow as tf"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"KpbkRBH45Rcf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"33527b3a-783a-4473-e67e-a75fcaafd4d3","executionInfo":{"status":"ok","timestamp":1552822409087,"user_tz":-330,"elapsed":1526,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"IXrn3heBaEJa"},"cell_type":"markdown","source":["## 2. Import MNIST data and create 2 datasets with one dataset having digits from 0 to 4 and other from 5 to 9 "]},{"metadata":{"colab_type":"code","id":"pjDuiK6ztgOK","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","# Load/Prep the Data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","split_condition1 = y_train <5\n","split_condition2 = y_train >=5\n","# labels = y_train[[y_train[5]]\n","x_train_Ind04 = x_train [split_condition1]\n","x_test_Ind04 = x_test [y_test<5]\n","y_train_Ind04 = y_train[split_condition1]\n","y_test_Ind04 = y_test[y_test<5]\n","\n","x_train_Ind59 = x_train [split_condition2]\n","x_test_Ind59 = x_test [y_test>=5]\n","y_train_Ind59 = y_train[split_condition2]\n","y_test_Ind59 = y_test[y_test>=5]\n","#mnist_df = mnist.load_data()\n","#split1, split2 = tf.split(value, num_or_size_splits=2, axis=1)\n","# df_1 = \n","# df_2 = \n","# x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') #\n","# x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n","# x_train /= 255 # normalization since we have max of 255\n","# x_test /= 255\n","# y_train = np_utils.to_categorical(y_train_num, 10) # since it is a classification problem we are explicitly mentioning this\n","# y_test = np_utils.to_categorical(y_test_num, 10)\n","\n","# print('--- THE DATA ---')\n","# print('x_train shape:', x_train.shape)\n","# print(x_train.shape[0], 'train samples')\n","# print(x_test.shape[0], 'test samples')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b64-b1rl70AR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"688b69b8-6b9e-4807-bbe1-e3183e1b6232","executionInfo":{"status":"ok","timestamp":1552822409532,"user_tz":-330,"elapsed":1937,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["y_train"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"colab_type":"text","id":"9qU14lYL9A5g"},"cell_type":"markdown","source":["## 3. Print x_train, y_train, x_test and y_test for both the datasets"]},{"metadata":{"colab_type":"code","id":"Z9OrszhJ0SgJ","colab":{"base_uri":"https://localhost:8080/","height":3654},"outputId":"ea48d5dd-4e6b-4b34-dd54-1c9f890e8830","executionInfo":{"status":"ok","timestamp":1552822409533,"user_tz":-330,"elapsed":1924,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["print('x_train after 1st half splitting is:',x_train_Ind04)\n","print('y_train after 1st half splitting is:',y_train_Ind04)\n","print('x_train after 2nd half splitting is:',x_train_Ind59)\n","print('x_train after 2nd half splitting is:',y_train_Ind59)\n","\n","print('x_test after 1st half splitting is:',x_test_Ind04)\n","print('y_test after 1st half splitting is:',y_test_Ind04)\n","print('x_test after 2nd half splitting is:',x_test_Ind59)\n","print('x_test after 2nd half splitting is:',y_test_Ind59)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["('x_train after 1st half splitting is:', array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8))\n","('y_train after 1st half splitting is:', array([0, 4, 1, ..., 2, 1, 3], dtype=uint8))\n","('x_train after 2nd half splitting is:', array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8))\n","('x_train after 2nd half splitting is:', array([5, 9, 5, ..., 5, 6, 8], dtype=uint8))\n","('x_test after 1st half splitting is:', array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8))\n","('y_test after 1st half splitting is:', array([2, 1, 0, ..., 2, 3, 4], dtype=uint8))\n","('x_test after 2nd half splitting is:', array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8))\n","('x_test after 2nd half splitting is:', array([7, 9, 5, ..., 9, 5, 6], dtype=uint8))\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"sJswV4xk9jQS","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"cB9BPFzr9oDF"},"cell_type":"markdown","source":["## ** 4. Let us take only the dataset (x_train, y_train, x_test, y_test) for Integers 0 to 4 in MNIST **\n","## Reshape x_train and x_test to a 4 Dimensional array (channel = 1) to pass it into a Conv2D layer"]},{"metadata":{"colab_type":"code","id":"FlQRPfFzaEJx","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"229430bb-7410-4767-aea9-31c889be8a80","executionInfo":{"status":"ok","timestamp":1552822409539,"user_tz":-330,"elapsed":1910,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["print(x_train_Ind04.shape)\n","print(y_train_Ind04.shape)\n","print(x_test_Ind04.shape)\n","print(y_test_Ind04.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(30596, 28, 28)\n","(30596,)\n","(5139, 28, 28)\n","(5139,)\n"],"name":"stdout"}]},{"metadata":{"id":"y1SDuEJCHU6m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"e8608078-d85d-4c46-8dc4-de9a28bad9c1","executionInfo":{"status":"ok","timestamp":1552822409541,"user_tz":-330,"elapsed":1898,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["import numpy as np\n","x_train_Ind04 = np.reshape(x_train_Ind04, (30596, 28, 28,1))\n","print(x_train_Ind04.shape)\n","x_test_Ind04 = np.reshape(x_test_Ind04, (5139, 28, 28,1))\n","print(x_test_Ind04.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(30596, 28, 28, 1)\n","(5139, 28, 28, 1)\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"jLQr-b3F-hw8"},"cell_type":"markdown","source":["## 5. Normalize x_train and x_test by dividing it by 255"]},{"metadata":{"colab_type":"code","id":"PlEZIAG5-g2I","colab":{"base_uri":"https://localhost:8080/","height":11181},"outputId":"9e5cd2db-3db5-4058-da13-22b87cd2ff0a","executionInfo":{"status":"ok","timestamp":1552822409908,"user_tz":-330,"elapsed":2256,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["x_train_Ind04_Normalized = x_train_Ind04/255\n","print(x_train_Ind04_Normalized)\n","x_test_Ind04_Normalized = x_test_Ind04/255\n","print(x_test_Ind04_Normalized)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[[[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," ...\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]]\n","[[[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," ...\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]]\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"pytVBaw4-vMi"},"cell_type":"markdown","source":["## 6. Use One-hot encoding to divide y_train and y_test into required no of output classes"]},{"metadata":{"colab_type":"code","id":"V48xiua4-uUi","colab":{"base_uri":"https://localhost:8080/","height":2345},"outputId":"2db1670e-ebcb-4c7f-9ead-417a888e703b","executionInfo":{"status":"ok","timestamp":1552822409909,"user_tz":-330,"elapsed":2237,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# convert class vectors to binary class matrices using one hot encoding\n","# y_train_Ind04_Onehot = keras.utils.to_categorical(y_train_Ind04)\n","# print(y_train_Ind04_Onehot)\n","# y_test_Ind04_Onehot = keras.utils.to_categorical(y_test_Ind04)\n","# print(y_test_Ind04_Onehot)\n","\n","# We use get dummies because when to categorical is used for one hot encoding, it takes from 0 to 4 and 5 to 9 instead of all the way from 0 to 9  even after splitting into 2 halves.\n","# so we go for get dummies and not to categorical\n","import pandas as pd\n","y_train_Ind04_Onehot = pd.get_dummies(y_train_Ind04)\n","print(y_train_Ind04_Onehot)\n","y_test_Ind04_Onehot = pd.get_dummies(y_test_Ind04)\n","print(y_test_Ind04_Onehot)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["       0  1  2  3  4\n","0      1  0  0  0  0\n","1      0  0  0  0  1\n","2      0  1  0  0  0\n","3      0  0  1  0  0\n","4      0  1  0  0  0\n","5      0  0  0  1  0\n","6      0  1  0  0  0\n","7      0  0  0  0  1\n","8      0  0  0  1  0\n","9      0  0  0  1  0\n","10     0  1  0  0  0\n","11     0  0  1  0  0\n","12     0  0  0  0  1\n","13     1  0  0  0  0\n","14     0  1  0  0  0\n","15     0  1  0  0  0\n","16     0  0  1  0  0\n","17     0  0  0  0  1\n","18     0  0  0  1  0\n","19     0  0  1  0  0\n","20     0  0  0  1  0\n","21     1  0  0  0  0\n","22     1  0  0  0  0\n","23     0  1  0  0  0\n","24     0  0  0  1  0\n","25     0  0  0  1  0\n","26     0  0  0  1  0\n","27     1  0  0  0  0\n","28     0  0  0  0  1\n","29     1  0  0  0  0\n","...   .. .. .. .. ..\n","30566  0  0  0  0  1\n","30567  1  0  0  0  0\n","30568  1  0  0  0  0\n","30569  0  0  0  0  1\n","30570  0  0  0  0  1\n","30571  1  0  0  0  0\n","30572  0  0  0  0  1\n","30573  1  0  0  0  0\n","30574  0  1  0  0  0\n","30575  0  0  0  1  0\n","30576  0  0  0  1  0\n","30577  0  1  0  0  0\n","30578  0  0  0  1  0\n","30579  0  0  0  1  0\n","30580  0  1  0  0  0\n","30581  0  0  1  0  0\n","30582  0  0  1  0  0\n","30583  1  0  0  0  0\n","30584  0  0  1  0  0\n","30585  0  0  0  0  1\n","30586  0  0  0  1  0\n","30587  0  1  0  0  0\n","30588  0  0  0  1  0\n","30589  0  0  1  0  0\n","30590  0  1  0  0  0\n","30591  0  0  1  0  0\n","30592  1  0  0  0  0\n","30593  0  0  1  0  0\n","30594  0  1  0  0  0\n","30595  0  0  0  1  0\n","\n","[30596 rows x 5 columns]\n","      0  1  2  3  4\n","0     0  0  1  0  0\n","1     0  1  0  0  0\n","2     1  0  0  0  0\n","3     0  0  0  0  1\n","4     0  1  0  0  0\n","5     0  0  0  0  1\n","6     1  0  0  0  0\n","7     1  0  0  0  0\n","8     0  1  0  0  0\n","9     0  0  0  1  0\n","10    0  0  0  0  1\n","11    0  0  0  0  1\n","12    1  0  0  0  0\n","13    0  0  0  0  1\n","14    1  0  0  0  0\n","15    0  1  0  0  0\n","16    0  0  0  1  0\n","17    0  1  0  0  0\n","18    0  0  0  1  0\n","19    0  0  0  0  1\n","20    0  0  1  0  0\n","21    0  1  0  0  0\n","22    0  0  1  0  0\n","23    0  1  0  0  0\n","24    0  1  0  0  0\n","25    0  0  0  0  1\n","26    0  0  1  0  0\n","27    0  0  0  1  0\n","28    0  1  0  0  0\n","29    0  0  1  0  0\n","...  .. .. .. .. ..\n","5109  0  0  0  0  1\n","5110  1  0  0  0  0\n","5111  0  1  0  0  0\n","5112  1  0  0  0  0\n","5113  1  0  0  0  0\n","5114  0  0  1  0  0\n","5115  0  1  0  0  0\n","5116  0  1  0  0  0\n","5117  0  0  0  0  1\n","5118  1  0  0  0  0\n","5119  1  0  0  0  0\n","5120  0  0  0  1  0\n","5121  0  1  0  0  0\n","5122  0  0  1  0  0\n","5123  0  0  0  0  1\n","5124  0  0  0  0  1\n","5125  0  0  0  1  0\n","5126  0  0  0  0  1\n","5127  0  1  0  0  0\n","5128  0  0  1  0  0\n","5129  1  0  0  0  0\n","5130  0  1  0  0  0\n","5131  0  0  1  0  0\n","5132  0  0  0  1  0\n","5133  0  0  0  0  1\n","5134  1  0  0  0  0\n","5135  0  1  0  0  0\n","5136  0  0  1  0  0\n","5137  0  0  0  1  0\n","5138  0  0  0  0  1\n","\n","[5139 rows x 5 columns]\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"elPkI44g_C2b"},"cell_type":"markdown","source":["## 7. Build a sequential model with 2 Convolutional layers with 32 kernels of size (3,3) followed by a Max pooling layer of size (2,2) followed by a drop out layer to be trained for classification of digits 0-4  "]},{"metadata":{"id":"oR8hhRmHaM-a","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.datasets import cifar10, mnist\n","from keras.models import Sequential# sequential is one type of model; there are graph models as well\n","from keras.layers import Dense, Activation, Dropout, Flatten, Reshape # Dense is fully connected layer\n","from keras.layers import Convolution2D, MaxPooling2D #\n","from keras.utils import np_utils\n","import pickle # serialization fancy word for storing on disk\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","plt.rcParams['figure.figsize'] = (15, 8)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"MU09mm9F89gO","colab":{"base_uri":"https://localhost:8080/","height":583},"outputId":"780c8135-3c5a-481a-98c8-e51cba7e264c","executionInfo":{"status":"ok","timestamp":1552822586847,"user_tz":-330,"elapsed":91560,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["TRAIN = False\n","BATCH_SIZE = 32\n","EPOCHS = 10 \n","\n","# Define the Type of Model\n","model2 = Sequential()\n","# 1st Conv Layer\n","model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28,1)))\n","model2.add(Activation('relu'))\n","\n","# 2nd Conv Layer\n","model2.add(Convolution2D(32, 3, 3))# input shape is known in the previous layer. so we don't give input shape\n","model2.add(Activation('relu'))\n","\n","# Fully Connected Layer\n","model2.add(Flatten())\n","model2.add(Dense(128))\n","model2.add(Activation('relu'))\n","\n","\n","# Layer 1\n","model2.add(Dense(output_dim=5, bias=True))\n","model2.add(Activation(\"softmax\"))\n","\n","# Loss and Optimizer\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Store Training Results\n","early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n","callback_list = [early_stopping]# [stats, early_stopping]\n","\n","# Train the model\n","model2.fit(x_train_Ind04_Normalized, y_train_Ind04_Onehot, nb_epoch=EPOCHS, batch_size=BATCH_SIZE,\n","        validation_data=(x_test_Ind04_Normalized, y_test_Ind04_Onehot), callbacks=callback_list, verbose=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n","  \n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n","  if sys.path[0] == '':\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=5, use_bias=True)`\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:34: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 30596 samples, validate on 5139 samples\n","Epoch 1/10\n","30596/30596 [==============================] - 14s 467us/step - loss: 1.1196 - acc: 0.5316 - val_loss: 1.0692 - val_acc: 0.5544\n","Epoch 2/10\n","30596/30596 [==============================] - 9s 309us/step - loss: 1.0524 - acc: 0.5559 - val_loss: 1.0616 - val_acc: 0.5610\n","Epoch 3/10\n","30596/30596 [==============================] - 9s 310us/step - loss: 1.0283 - acc: 0.5638 - val_loss: 1.0447 - val_acc: 0.5666\n","Epoch 4/10\n","30596/30596 [==============================] - 9s 308us/step - loss: 1.0116 - acc: 0.5719 - val_loss: 1.0398 - val_acc: 0.5698\n","Epoch 5/10\n","30596/30596 [==============================] - 9s 310us/step - loss: 0.9961 - acc: 0.5760 - val_loss: 1.0530 - val_acc: 0.5593\n","Epoch 6/10\n","30596/30596 [==============================] - 9s 308us/step - loss: 0.9842 - acc: 0.5818 - val_loss: 1.0515 - val_acc: 0.5647\n","Epoch 7/10\n","30596/30596 [==============================] - 9s 308us/step - loss: 0.9746 - acc: 0.5849 - val_loss: 1.0594 - val_acc: 0.5651\n","Epoch 8/10\n","30596/30596 [==============================] - 9s 309us/step - loss: 0.9646 - acc: 0.5866 - val_loss: 1.0572 - val_acc: 0.5655\n","Epoch 9/10\n","30596/30596 [==============================] - 9s 309us/step - loss: 0.9563 - acc: 0.5919 - val_loss: 1.0542 - val_acc: 0.5626\n","Epoch 00009: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe071315f90>"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"colab_type":"text","id":"sJQaycRO_3Au"},"cell_type":"markdown","source":["## 8. Post that flatten the data and add 2 Dense layers with 128 neurons and neurons = output classes with activation = 'relu' and 'softmax' respectively. Add dropout layer inbetween if necessary  "]},{"metadata":{"colab_type":"code","id":"vOZeRbK7t9AT","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"my1P09bxAv8H"},"cell_type":"markdown","source":["## 9. Print the training and test accuracy"]},{"metadata":{"colab_type":"code","id":"yf7F8Gdutbf0","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"f62472f7-bd96-4945-e6e4-fa11a04cc706","executionInfo":{"status":"ok","timestamp":1552823052242,"user_tz":-330,"elapsed":3942,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["model2.evaluate(x_train_Ind04, y_train_Ind04_Onehot)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["30596/30596 [==============================] - 3s 91us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.541231201556238, 0.9662701006667538]"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"_N7eUBiHcRbX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"7a1055d9-9cf4-4b02-f72d-293b128b6e14","executionInfo":{"status":"ok","timestamp":1552823207172,"user_tz":-330,"elapsed":1594,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["model2.evaluate(x_test_Ind04, y_test_Ind04_Onehot)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["5139/5139 [==============================] - 0s 93us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.5016521055612138, 0.9686709477363753]"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"colab_type":"text","id":"z78o3WIjaEJ3"},"cell_type":"markdown","source":["## 10. Make only the dense layers to be trainable and convolutional layers to be non-trainable"]},{"metadata":{"colab_type":"code","id":"brN7VZHFaEJ4","colab":{"base_uri":"https://localhost:8080/","height":345},"outputId":"951dafb0-90c1-45da-dfd5-edba2c1defb8","executionInfo":{"status":"ok","timestamp":1552823003197,"user_tz":-330,"elapsed":1004,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["#Freezing layers in the model which don't have 'dense' in their name\n","for layer in model2.layers:\n","  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n","    #Freezing a layer\n","    layer.trainable = False # freezing the layer\n","\n","#Module to print colourful statements\n","from termcolor import colored\n","\n","#Check which layers have been frozen \n","for layer in model2.layers:\n","  print (colored(layer.name, 'blue'))\n","  print (colored(layer.trainable, 'red'))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\u001b[34mconv2d_3\u001b[0m\n","\u001b[31mFalse\u001b[0m\n","\u001b[34mactivation_5\u001b[0m\n","\u001b[31mFalse\u001b[0m\n","\u001b[34mconv2d_4\u001b[0m\n","\u001b[31mFalse\u001b[0m\n","\u001b[34mactivation_6\u001b[0m\n","\u001b[31mFalse\u001b[0m\n","\u001b[34mflatten_2\u001b[0m\n","\u001b[31mFalse\u001b[0m\n","\u001b[34mdense_3\u001b[0m\n","\u001b[31mTrue\u001b[0m\n","\u001b[34mactivation_7\u001b[0m\n","\u001b[31mFalse\u001b[0m\n","\u001b[34mdense_4\u001b[0m\n","\u001b[31mTrue\u001b[0m\n","\u001b[34mactivation_8\u001b[0m\n","\u001b[31mFalse\u001b[0m\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"4opnW7o0BJ8P"},"cell_type":"markdown","source":["## 11. Use the model trained on 0 to 4 digit classification and train it on the dataset which has digits 5 to 9  (Using Transfer learning keeping only the dense layers to be trainable)"]},{"metadata":{"colab_type":"code","id":"lCFcYHTm6-cE","colab":{"base_uri":"https://localhost:8080/","height":90},"outputId":"513831a1-834b-42c2-ae2c-f78fc00d5e69","executionInfo":{"status":"ok","timestamp":1552824900206,"user_tz":-330,"elapsed":1106,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# repeat all the pre-processing steps for 5 to 9 like in 0 to 4 and then use the 0 to 4 model's learning via transfer learning to 5 to 9 data set\n","print(x_train_Ind59.shape)\n","print(y_train_Ind59.shape)\n","print(x_test_Ind59.shape)\n","print(y_test_Ind59.shape)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["(29404, 28, 28)\n","(29404,)\n","(4861, 28, 28)\n","(4861,)\n"],"name":"stdout"}]},{"metadata":{"id":"YMl9Vro0fjOO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"8c224e7a-e1d7-4f75-e885-4892ac12e709","executionInfo":{"status":"ok","timestamp":1552824903354,"user_tz":-330,"elapsed":1113,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["import numpy as np\n","x_train_Ind59 = np.reshape(x_train_Ind59,(x_train_Ind59.shape[0], 28, 28,1))\n","print(x_train_Ind59.shape)\n","x_test_Ind59 = np.reshape(x_test_Ind59,(x_test_Ind59.shape[0], 28, 28,1))\n","print(x_test_Ind59.shape)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["(29404, 28, 28, 1)\n","(4861, 28, 28, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"iNxTHmK3fjSa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":11181},"outputId":"bb8eb773-e602-4cf8-b3b8-96817026af66","executionInfo":{"status":"ok","timestamp":1552824909072,"user_tz":-330,"elapsed":1175,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# Normalizing the data\n","x_train_Ind59_Normalized = x_train_Ind59/255\n","print(x_train_Ind59_Normalized)\n","x_test_Ind59_Normalized = x_test_Ind59/255\n","print(x_test_Ind59_Normalized)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["[[[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," ...\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]]\n","[[[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," ...\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]\n","\n","\n"," [[[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  ...\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]\n","\n","  [[0]\n","   [0]\n","   [0]\n","   ...\n","   [0]\n","   [0]\n","   [0]]]]\n"],"name":"stdout"}]},{"metadata":{"id":"GZ-WF3Q-fjMl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2345},"outputId":"f77af1c8-7ac6-4d1b-c772-5045415aa233","executionInfo":{"status":"ok","timestamp":1552824911120,"user_tz":-330,"elapsed":1039,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# We use get dummies because when to categorical is used for one hot encoding, it takes from 0 to 4 and 5 to 9 instead of all the way from 0 to 9  even after splitting into 2 halves.\n","# so we go for get dummies and not to categorical\n","import pandas as pd\n","y_train_Ind59_Onehot = pd.get_dummies(y_train_Ind59)\n","print(y_train_Ind59_Onehot)\n","y_test_Ind59_Onehot = pd.get_dummies(y_test_Ind59)\n","print(y_test_Ind59_Onehot)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["       5  6  7  8  9\n","0      1  0  0  0  0\n","1      0  0  0  0  1\n","2      1  0  0  0  0\n","3      0  1  0  0  0\n","4      0  0  1  0  0\n","5      0  0  0  1  0\n","6      0  1  0  0  0\n","7      0  0  0  0  1\n","8      0  0  0  0  1\n","9      0  0  1  0  0\n","10     0  0  0  1  0\n","11     0  1  0  0  0\n","12     0  0  0  0  1\n","13     1  0  0  0  0\n","14     0  1  0  0  0\n","15     0  0  1  0  0\n","16     0  1  0  0  0\n","17     0  0  0  1  0\n","18     0  0  1  0  0\n","19     0  0  0  0  1\n","20     0  0  0  0  1\n","21     0  0  0  1  0\n","22     1  0  0  0  0\n","23     0  0  0  0  1\n","24     0  0  1  0  0\n","25     0  0  0  0  1\n","26     0  0  0  1  0\n","27     0  0  0  0  1\n","28     0  1  0  0  0\n","29     1  0  0  0  0\n","...   .. .. .. .. ..\n","29374  0  0  0  1  0\n","29375  1  0  0  0  0\n","29376  0  0  0  0  1\n","29377  0  0  0  1  0\n","29378  0  0  0  1  0\n","29379  0  0  1  0  0\n","29380  1  0  0  0  0\n","29381  0  1  0  0  0\n","29382  1  0  0  0  0\n","29383  0  0  0  1  0\n","29384  0  0  1  0  0\n","29385  0  1  0  0  0\n","29386  0  0  0  1  0\n","29387  1  0  0  0  0\n","29388  0  0  0  0  1\n","29389  0  0  0  0  1\n","29390  0  1  0  0  0\n","29391  0  0  1  0  0\n","29392  0  1  0  0  0\n","29393  0  1  0  0  0\n","29394  0  1  0  0  0\n","29395  0  0  1  0  0\n","29396  0  0  0  1  0\n","29397  0  0  0  0  1\n","29398  0  0  0  0  1\n","29399  1  0  0  0  0\n","29400  0  0  0  1  0\n","29401  1  0  0  0  0\n","29402  0  1  0  0  0\n","29403  0  0  0  1  0\n","\n","[29404 rows x 5 columns]\n","      5  6  7  8  9\n","0     0  0  1  0  0\n","1     0  0  0  0  1\n","2     1  0  0  0  0\n","3     0  0  0  0  1\n","4     0  1  0  0  0\n","5     0  0  0  0  1\n","6     1  0  0  0  0\n","7     0  0  0  0  1\n","8     0  0  1  0  0\n","9     0  0  0  0  1\n","10    0  1  0  0  0\n","11    0  1  0  0  0\n","12    1  0  0  0  0\n","13    0  0  1  0  0\n","14    0  0  1  0  0\n","15    0  0  1  0  0\n","16    0  0  1  0  0\n","17    1  0  0  0  0\n","18    0  1  0  0  0\n","19    1  0  0  0  0\n","20    1  0  0  0  0\n","21    0  1  0  0  0\n","22    0  0  0  0  1\n","23    1  0  0  0  0\n","24    0  0  1  0  0\n","25    0  0  0  1  0\n","26    0  0  0  0  1\n","27    0  0  1  0  0\n","28    0  1  0  0  0\n","29    0  0  1  0  0\n","...  .. .. .. .. ..\n","4831  0  0  0  1  0\n","4832  0  0  1  0  0\n","4833  0  0  0  1  0\n","4834  0  1  0  0  0\n","4835  0  1  0  0  0\n","4836  1  0  0  0  0\n","4837  0  0  0  0  1\n","4838  0  1  0  0  0\n","4839  0  1  0  0  0\n","4840  0  0  1  0  0\n","4841  0  0  1  0  0\n","4842  0  0  0  1  0\n","4843  0  1  0  0  0\n","4844  0  0  1  0  0\n","4845  0  1  0  0  0\n","4846  0  0  0  1  0\n","4847  0  0  1  0  0\n","4848  1  0  0  0  0\n","4849  0  0  0  0  1\n","4850  0  1  0  0  0\n","4851  0  0  1  0  0\n","4852  0  1  0  0  0\n","4853  1  0  0  0  0\n","4854  1  0  0  0  0\n","4855  0  1  0  0  0\n","4856  0  0  1  0  0\n","4857  0  0  0  1  0\n","4858  0  0  0  0  1\n","4859  1  0  0  0  0\n","4860  0  1  0  0  0\n","\n","[4861 rows x 5 columns]\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"DITyAt3t7Tto","colab":{"base_uri":"https://localhost:8080/","height":528},"outputId":"fc800db0-e754-4014-ff75-1c06a8910e81","executionInfo":{"status":"ok","timestamp":1552825003270,"user_tz":-330,"elapsed":91169,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["\n","# Train the model\n","model2.fit(x_train_Ind59_Normalized, y_train_Ind59_Onehot, nb_epoch=EPOCHS, batch_size=BATCH_SIZE,\n","        validation_data=(x_test_Ind59_Normalized, y_test_Ind59_Onehot), callbacks=callback_list, verbose=True)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Train on 29404 samples, validate on 4861 samples\n","Epoch 1/10\n","  480/29404 [..............................] - ETA: 11s - loss: 1.9384 - acc: 0.2521"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \n","/usr/local/lib/python2.7/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["29404/29404 [==============================] - 9s 310us/step - loss: 1.1509 - acc: 0.5195 - val_loss: 1.0555 - val_acc: 0.5542\n","Epoch 2/10\n","29404/29404 [==============================] - 9s 307us/step - loss: 1.0111 - acc: 0.5810 - val_loss: 1.0480 - val_acc: 0.5610\n","Epoch 3/10\n","29404/29404 [==============================] - 9s 307us/step - loss: 0.9766 - acc: 0.5947 - val_loss: 1.0364 - val_acc: 0.5668\n","Epoch 4/10\n","29404/29404 [==============================] - 9s 307us/step - loss: 0.9541 - acc: 0.6036 - val_loss: 1.0419 - val_acc: 0.5715\n","Epoch 5/10\n","29404/29404 [==============================] - 9s 306us/step - loss: 0.9361 - acc: 0.6101 - val_loss: 1.0404 - val_acc: 0.5735\n","Epoch 6/10\n","29404/29404 [==============================] - 9s 307us/step - loss: 0.9200 - acc: 0.6158 - val_loss: 1.0579 - val_acc: 0.5703\n","Epoch 7/10\n","29404/29404 [==============================] - 9s 308us/step - loss: 0.9060 - acc: 0.6212 - val_loss: 1.0751 - val_acc: 0.5666\n","Epoch 8/10\n","29404/29404 [==============================] - 9s 306us/step - loss: 0.8968 - acc: 0.6245 - val_loss: 1.0798 - val_acc: 0.5659\n","Epoch 9/10\n","29404/29404 [==============================] - 9s 307us/step - loss: 0.8896 - acc: 0.6264 - val_loss: 1.0733 - val_acc: 0.5668\n","Epoch 10/10\n","29404/29404 [==============================] - 9s 307us/step - loss: 0.8833 - acc: 0.6291 - val_loss: 1.0920 - val_acc: 0.5672\n","Epoch 00010: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe07169ca90>"]},"metadata":{"tags":[]},"execution_count":34}]},{"metadata":{"colab_type":"text","id":"SoDozqghCJZ4"},"cell_type":"markdown","source":["## 12. Print the accuracy for classification of digits 5 to 9"]},{"metadata":{"colab_type":"code","id":"9fCxgb5s49Cj","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"0e734aa4-0363-44ba-b01f-2862f6e00cba","executionInfo":{"status":"ok","timestamp":1552825077201,"user_tz":-330,"elapsed":3469,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["model2.evaluate(x_train_Ind59, y_train_Ind59_Onehot)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["29404/29404 [==============================] - 3s 91us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.6506695222583185, 0.8972928853136166]"]},"metadata":{"tags":[]},"execution_count":35}]},{"metadata":{"colab_type":"code","id":"LRWizZIpCUKg","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"2946d00a-56e6-4237-d31b-680dc8152d68","executionInfo":{"status":"ok","timestamp":1552825078744,"user_tz":-330,"elapsed":1139,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["model2.evaluate(x_test_Ind59, y_test_Ind59_Onehot)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["4861/4861 [==============================] - 0s 93us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.6413236474627895, 0.8981691011429029]"]},"metadata":{"tags":[]},"execution_count":36}]},{"metadata":{"id":"FU-HwvIdH0M-","colab_type":"text"},"cell_type":"markdown","source":["## Sentiment analysis <br> \n","\n","The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n","Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."]},{"metadata":{"id":"nAQDiZHRH0M_","colab_type":"text"},"cell_type":"markdown","source":["### 13. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"]},{"metadata":{"id":"3eXGIe-SH0NA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"47b3e0cd-bb76-43e9-eba7-73caef299a90","executionInfo":{"status":"ok","timestamp":1552825326277,"user_tz":-330,"elapsed":863,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount ('/content/drive/')"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"dIRyO5ucmaZK","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CWeWe1eJH0NF","colab_type":"code","colab":{}},"cell_type":"code","source":["tweets_df = pd.read_csv('tweets.csv').dropna()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jPJvTjefH0NI","colab_type":"text"},"cell_type":"markdown","source":["### 14. Preprocess the text and add the preprocessed text in a column with name `text` in the dataframe."]},{"metadata":{"id":"5iec5s9gH0NI","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess(text):\n","    try:\n","        return text.decode('ascii')\n","    except Exception as e:\n","        return \"\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"EQSmqA-vH0NT","colab_type":"code","colab":{}},"cell_type":"code","source":["tweets_df['text'] = [preprocess(text) for text in tweets_df.tweet_text]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7kX-WoJDH0NV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":285},"outputId":"8e049623-7be1-4a5c-c429-9fb3aa3110fb","executionInfo":{"status":"ok","timestamp":1552827460370,"user_tz":-330,"elapsed":1420,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["tweets_df.head(5)"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>emotion_in_tweet_is_directed_at</th>\n","      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n","      <td>iPhone</td>\n","      <td>Negative emotion</td>\n","      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n","      <td>iPad or iPhone App</td>\n","      <td>Positive emotion</td>\n","      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n","      <td>iPad</td>\n","      <td>Positive emotion</td>\n","      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@sxsw I hope this year's festival isn't as cra...</td>\n","      <td>iPad or iPhone App</td>\n","      <td>Negative emotion</td>\n","      <td>@sxsw I hope this year's festival isn't as cra...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n","      <td>Google</td>\n","      <td>Positive emotion</td>\n","      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          tweet_text  \\\n","0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n","1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n","2  @swonderlin Can not wait for #iPad 2 also. The...   \n","3  @sxsw I hope this year's festival isn't as cra...   \n","4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n","\n","  emotion_in_tweet_is_directed_at  \\\n","0                          iPhone   \n","1              iPad or iPhone App   \n","2                            iPad   \n","3              iPad or iPhone App   \n","4                          Google   \n","\n","  is_there_an_emotion_directed_at_a_brand_or_product  \\\n","0                                   Negative emotion   \n","1                                   Positive emotion   \n","2                                   Positive emotion   \n","3                                   Negative emotion   \n","4                                   Positive emotion   \n","\n","                                                text  \n","0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  \n","1  @jessedee Know about @fludapp ? Awesome iPad/i...  \n","2  @swonderlin Can not wait for #iPad 2 also. The...  \n","3  @sxsw I hope this year's festival isn't as cra...  \n","4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  "]},"metadata":{"tags":[]},"execution_count":69}]},{"metadata":{"id":"5Q-gCNFao1FO","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"OGWB3P2WH0NY","colab_type":"text"},"cell_type":"markdown","source":["### 15. Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."]},{"metadata":{"id":"bdgA_8N2H0NY","colab_type":"code","colab":{}},"cell_type":"code","source":["tweets_df = tweets_df[(tweets_df.is_there_an_emotion_directed_at_a_brand_or_product == 'Negative emotion') | (tweets_df.is_there_an_emotion_directed_at_a_brand_or_product =='Positive emotion')]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_Jlu-reIH0Na","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SotCRvkDH0Nf","colab_type":"text"},"cell_type":"markdown","source":["### 16. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n","\n","#### Use `vect` as the variable name for initialising CountVectorizer."]},{"metadata":{"id":"YcbkY4sgH0Ng","colab_type":"code","colab":{}},"cell_type":"code","source":["# use CountVectorizer to create document-term matrices from X_train and X_test\n","from sklearn.feature_extraction.text import CountVectorizer\n","vect = CountVectorizer()\n","tweets_df_dtm = vect.fit_transform(tweets_df['text'])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KyXtZGr-H0Nl","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z4LUM-XPH0Nn","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"aIdZYxJtH0Nq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"5pxd5fSHH0Nt","colab_type":"text"},"cell_type":"markdown","source":["### 17. Find number of different words in vocabulary"]},{"metadata":{"id":"p1DQ2LdNH0Nu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1199},"outputId":"abde248a-cd0a-45db-d370-1b0ed4d38032","executionInfo":{"status":"ok","timestamp":1552827463548,"user_tz":-330,"elapsed":597,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["dir(vect)"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['__class__',\n"," '__delattr__',\n"," '__dict__',\n"," '__doc__',\n"," '__format__',\n"," '__getattribute__',\n"," '__getstate__',\n"," '__hash__',\n"," '__init__',\n"," '__module__',\n"," '__new__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__setstate__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__weakref__',\n"," '_char_ngrams',\n"," '_char_wb_ngrams',\n"," '_check_stop_words_consistency',\n"," '_check_vocabulary',\n"," '_count_vocab',\n"," '_get_param_names',\n"," '_limit_features',\n"," '_sort_features',\n"," '_stop_words_id',\n"," '_validate_params',\n"," '_validate_vocabulary',\n"," '_white_spaces',\n"," '_word_ngrams',\n"," 'analyzer',\n"," 'binary',\n"," 'build_analyzer',\n"," 'build_preprocessor',\n"," 'build_tokenizer',\n"," 'decode',\n"," 'decode_error',\n"," 'dtype',\n"," 'encoding',\n"," 'fit',\n"," 'fit_transform',\n"," 'fixed_vocabulary_',\n"," 'get_feature_names',\n"," 'get_params',\n"," 'get_stop_words',\n"," 'input',\n"," 'inverse_transform',\n"," 'lowercase',\n"," 'max_df',\n"," 'max_features',\n"," 'min_df',\n"," 'ngram_range',\n"," 'preprocessor',\n"," 'set_params',\n"," 'stop_words',\n"," 'stop_words_',\n"," 'strip_accents',\n"," 'token_pattern',\n"," 'tokenizer',\n"," 'transform',\n"," 'vocabulary',\n"," 'vocabulary_']"]},"metadata":{"tags":[]},"execution_count":72}]},{"metadata":{"id":"dwtgjTBeH0Ny","colab_type":"text"},"cell_type":"markdown","source":["#### Tip: To see all available functions for an Object use dir"]},{"metadata":{"id":"2n_iCcTNH0N0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"798692d3-4929-4104-846b-b69ab730fea5","executionInfo":{"status":"ok","timestamp":1552827465367,"user_tz":-330,"elapsed":713,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["print(len(vect.get_feature_names()))"],"execution_count":73,"outputs":[{"output_type":"stream","text":["5482\n"],"name":"stdout"}]},{"metadata":{"id":"ShA6D8jKH0N5","colab_type":"text"},"cell_type":"markdown","source":["### 18. Find out how many Positive and Negative emotions are there.\n","\n","Hint: Use value_counts on that column"]},{"metadata":{"id":"q7LAl5pzH0N6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"2d3def24-ee7e-49da-ba74-59fbcb176689","executionInfo":{"status":"ok","timestamp":1552827466837,"user_tz":-330,"elapsed":930,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Positive emotion    2672\n","Negative emotion     519\n","Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"]},"metadata":{"tags":[]},"execution_count":74}]},{"metadata":{"id":"IUvgj0FoH0N9","colab_type":"text"},"cell_type":"markdown","source":["### 19. Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'Label'\n","\n","Hint: use map on that column and give labels"]},{"metadata":{"id":"YftKwFv7H0N9","colab_type":"code","colab":{}},"cell_type":"code","source":["tweets_df['Label'] = tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].map({'Positive emotion':1,'Negative emotion':0})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3YErwYLCH0N_","colab_type":"text"},"cell_type":"markdown","source":["### 20. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"]},{"metadata":{"id":"lNkwrGgEH0OA","colab_type":"code","colab":{}},"cell_type":"code","source":["X = tweets_df['text']\n","y = tweets_df['Label']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gCr_3zD2qt8U","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q5nlCuaaH0OD","colab_type":"text"},"cell_type":"markdown","source":["## 21. **Predicting the sentiment:**\n","\n","\n","### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"]},{"metadata":{"id":"IU0vdrWzu8z5","colab_type":"code","colab":{}},"cell_type":"code","source":["#tweets_df['Label']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2AbVYssaH0OE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8bf0effe-e42e-4b28-dde1-9f0db3f46de1","executionInfo":{"status":"ok","timestamp":1552827768630,"user_tz":-330,"elapsed":962,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# use default options for CountVectorizer\n","#vect = CountVectorizer()\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.naive_bayes import MultinomialNB\n","vect = CountVectorizer(ngram_range=(1,2))\n","\n","# create document-term matrices\n","X_train_dtm = vect.fit_transform(X_train)\n","X_test_dtm = vect.transform(X_test)\n","\n","# use Naive Bayes to predict the star rating\n","nb = MultinomialNB()\n","nb.fit(X_train_dtm, y_train)\n","y_pred_class = nb.predict(X_test_dtm)\n","\n","# calculate accuracy\n","print (accuracy_score(y_test, y_pred_class))"],"execution_count":90,"outputs":[{"output_type":"stream","text":["0.8748043818466353\n"],"name":"stdout"}]},{"metadata":{"id":"ktXrLhmOH0Of","colab_type":"code","colab":{}},"cell_type":"code","source":["# import and instantiate a logistic regression model\n","from sklearn.linear_model import LogisticRegression\n","logreg = LogisticRegression()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"clv2X0kKH0Ok","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":146},"outputId":"86dd5bc6-8519-40d7-c0fa-11a1496eb1b6","executionInfo":{"status":"ok","timestamp":1552828624173,"user_tz":-330,"elapsed":969,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# train the model using X_train_dtm\n","logreg.fit(X_train_dtm, y_train)"],"execution_count":94,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='warn',\n","          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":94}]},{"metadata":{"id":"K86LRMfdH0Ou","colab_type":"code","colab":{}},"cell_type":"code","source":["# make class predictions for X_test_dtm\n","y_pred_class = logreg.predict(X_test_dtm)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CHDOcqiVzMgy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2345},"outputId":"2e9e6791-e95f-4aa5-8d86-3ae3addcf8d7","executionInfo":{"status":"ok","timestamp":1552828677704,"user_tz":-330,"elapsed":912,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# calculate predicted probabilities for X_test_dtm\n","y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n","y_pred_prob"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.96635096, 0.94900332, 0.99466192, 0.8342472 , 0.8478717 ,\n","       0.95781765, 0.99784265, 0.98368943, 0.97299314, 0.93547715,\n","       0.98742885, 0.72335086, 0.97874119, 0.96398002, 0.98315055,\n","       0.95221503, 0.88628961, 0.99376448, 0.06183564, 0.98516375,\n","       0.97159072, 0.91527306, 0.98802102, 0.99343684, 0.96172606,\n","       0.8478717 , 0.98198695, 0.95804287, 0.95182612, 0.9179835 ,\n","       0.99611237, 0.99412396, 0.78378835, 0.8478717 , 0.86316186,\n","       0.54977833, 0.81865456, 0.98894488, 0.95300733, 0.93956819,\n","       0.99313416, 0.95051353, 0.66898249, 0.97983331, 0.98469979,\n","       0.9883219 , 0.97447512, 0.98463811, 0.9898438 , 0.93660198,\n","       0.96895819, 0.99571629, 0.90612694, 0.98422309, 0.9637837 ,\n","       0.99115833, 0.94838627, 0.98973383, 0.99351141, 0.88805914,\n","       0.97192283, 0.98083342, 0.91941782, 0.99757644, 0.99181968,\n","       0.96535638, 0.98617801, 0.95105563, 0.97204811, 0.96472183,\n","       0.97444635, 0.98201112, 0.98289906, 0.98939796, 0.96831601,\n","       0.87314755, 0.90383712, 0.99382911, 0.8643915 , 0.99076133,\n","       0.98030944, 0.8478717 , 0.91280748, 0.99267523, 0.80231264,\n","       0.99342546, 0.87987725, 0.73622041, 0.97015443, 0.99177857,\n","       0.98900493, 0.96295694, 0.94833966, 0.94498671, 0.82930007,\n","       0.98804425, 0.94241975, 0.99320073, 0.87193747, 0.78092202,\n","       0.94677173, 0.9908996 , 0.93478946, 0.96093766, 0.90505039,\n","       0.99637813, 0.70729859, 0.88800193, 0.99559243, 0.97305804,\n","       0.99394236, 0.84994397, 0.94367994, 0.97421569, 0.8478717 ,\n","       0.19789876, 0.99592636, 0.92445769, 0.99765211, 0.98287306,\n","       0.94092218, 0.98743975, 0.07497419, 0.99467655, 0.02284778,\n","       0.99364801, 0.9793647 , 0.96268657, 0.8478717 , 0.92230197,\n","       0.9031839 , 0.9675852 , 0.8478717 , 0.98332131, 0.99083879,\n","       0.93298182, 0.97558431, 0.98920484, 0.99390584, 0.912978  ,\n","       0.94486607, 0.96267893, 0.99321425, 0.82966605, 0.96372446,\n","       0.8478717 , 0.97204652, 0.97677801, 0.6070656 , 0.36893211,\n","       0.92838632, 0.98015446, 0.96449803, 0.99861203, 0.97057644,\n","       0.99759168, 0.3716941 , 0.85934281, 0.98319066, 0.96783625,\n","       0.96530742, 0.92770242, 0.94129822, 0.81393834, 0.99109739,\n","       0.40579173, 0.90459407, 0.95389274, 0.95161891, 0.984259  ,\n","       0.9825495 , 0.83672756, 0.9879723 , 0.9710094 , 0.97252723,\n","       0.99015571, 0.8910837 , 0.9496191 , 0.77994708, 0.98835455,\n","       0.75099372, 0.95650671, 0.04945416, 0.98343134, 0.91151973,\n","       0.89402516, 0.93369216, 0.94768723, 0.99433532, 0.2337075 ,\n","       0.99527123, 0.98606079, 0.8478717 , 0.90200042, 0.81767129,\n","       0.79934031, 0.89137384, 0.95605289, 0.97205815, 0.99170546,\n","       0.9830361 , 0.95362862, 0.95967438, 0.98801215, 0.9078716 ,\n","       0.90502103, 0.96051314, 0.87818151, 0.77727068, 0.98876083,\n","       0.8478717 , 0.99109855, 0.16290501, 0.9962652 , 0.92151121,\n","       0.93030945, 0.97478629, 0.99947375, 0.67590339, 0.3169996 ,\n","       0.98833851, 0.98961833, 0.8478717 , 0.98806901, 0.91675803,\n","       0.08322863, 0.99081627, 0.91374585, 0.9946141 , 0.9949816 ,\n","       0.87388413, 0.80622886, 0.92845359, 0.81868352, 0.98702311,\n","       0.99213662, 0.84482109, 0.99388137, 0.99521619, 0.8478717 ,\n","       0.98541443, 0.93450697, 0.99325385, 0.9035411 , 0.97787207,\n","       0.99971647, 0.76070456, 0.96475457, 0.98728448, 0.98699658,\n","       0.20927853, 0.96341149, 0.8478717 , 0.96486588, 0.93441613,\n","       0.93800584, 0.97656081, 0.98726553, 0.98582617, 0.55633438,\n","       0.99801933, 0.99262552, 0.8478717 , 0.98412868, 0.84351468,\n","       0.66002722, 0.98572018, 0.97414499, 0.96613653, 0.54616112,\n","       0.96735064, 0.9989337 , 0.92298036, 0.90827167, 0.93863295,\n","       0.80023967, 0.63074526, 0.99561864, 0.62793618, 0.8478717 ,\n","       0.98669001, 0.95588586, 0.9924375 , 0.45280264, 0.99530663,\n","       0.98918412, 0.8789682 , 0.94396759, 0.98358038, 0.98739828,\n","       0.99209746, 0.93505787, 0.91643365, 0.99684456, 0.97864601,\n","       0.98892292, 0.8478717 , 0.94115749, 0.88095902, 0.98119289,\n","       0.9907303 , 0.98451341, 0.8478717 , 0.95707165, 0.96164093,\n","       0.72025618, 0.96706287, 0.8478717 , 0.22031194, 0.96200597,\n","       0.97703868, 0.11460436, 0.93396717, 0.98742709, 0.96859684,\n","       0.93929514, 0.98895668, 0.96918733, 0.95517669, 0.99708458,\n","       0.97002293, 0.77270243, 0.99526417, 0.76938832, 0.94077731,\n","       0.87118108, 0.99321772, 0.95034323, 0.51495751, 0.58375361,\n","       0.52355609, 0.81958006, 0.89227122, 0.95224185, 0.22945829,\n","       0.8478717 , 0.9387141 , 0.96696667, 0.87933356, 0.86760587,\n","       0.70972848, 0.99432351, 0.9941726 , 0.99141126, 0.770472  ,\n","       0.91033079, 0.94666539, 0.923498  , 0.87473268, 0.99343338,\n","       0.98983223, 0.95444006, 0.98290565, 0.85833051, 0.8478717 ,\n","       0.98194387, 0.99410446, 0.99688571, 0.86835109, 0.90870923,\n","       0.95411255, 0.95487745, 0.99722617, 0.98422119, 0.99658208,\n","       0.93295733, 0.85388817, 0.92583465, 0.61143012, 0.98504238,\n","       0.9819185 , 0.97673794, 0.76471446, 0.04736635, 0.98695893,\n","       0.1691824 , 0.9876283 , 0.94743685, 0.98901968, 0.99049015,\n","       0.85519092, 0.19925916, 0.96113501, 0.81808218, 0.88429286,\n","       0.98255013, 0.97328569, 0.99919749, 0.89957165, 0.99100598,\n","       0.99108551, 0.74694876, 0.99292309, 0.91075307, 0.94226268,\n","       0.957806  , 0.9962173 , 0.99793524, 0.98994837, 0.98394341,\n","       0.99808566, 0.83405447, 0.98742278, 0.84467672, 0.95145996,\n","       0.76518331, 0.91932908, 0.67538502, 0.94056886, 0.94645872,\n","       0.99817812, 0.94611696, 0.83231684, 0.8478717 , 0.13135195,\n","       0.98091768, 0.73270293, 0.94280305, 0.92195722, 0.98718858,\n","       0.89630508, 0.87776726, 0.96319319, 0.99857526, 0.96880927,\n","       0.8706763 , 0.98410102, 0.94268803, 0.99580101, 0.91392629,\n","       0.8478717 , 0.96470916, 0.9895457 , 0.09335956, 0.95610353,\n","       0.84226298, 0.95406245, 0.96118672, 0.96765157, 0.95621013,\n","       0.92883893, 0.98729946, 0.58706051, 0.98835634, 0.96815537,\n","       0.78007819, 0.99496278, 0.41486873, 0.98360548, 0.96332451,\n","       0.97205067, 0.93862851, 0.89449784, 0.86009661, 0.98925811,\n","       0.94275651, 0.62894573, 0.92901677, 0.96649506, 0.90472716,\n","       0.96414814, 0.94986177, 0.98994497, 0.99053934, 0.91596198,\n","       0.21068211, 0.8478717 , 0.8478717 , 0.80826415, 0.98049567,\n","       0.977915  , 0.73920482, 0.98120975, 0.8478717 , 0.73271661,\n","       0.97795874, 0.8478717 , 0.98977756, 0.93086357, 0.9956077 ,\n","       0.03915921, 0.95730133, 0.94281816, 0.12104891, 0.9961581 ,\n","       0.99816029, 0.94679542, 0.9270115 , 0.8478717 , 0.99592374,\n","       0.8478717 , 0.96844718, 0.69072037, 0.99828696, 0.76991742,\n","       0.91459014, 0.99606387, 0.99810489, 0.80140564, 0.57263375,\n","       0.96172037, 0.96758324, 0.97262448, 0.1169525 , 0.90833295,\n","       0.99270686, 0.90389705, 0.58674221, 0.99636728, 0.85067619,\n","       0.96351383, 0.99238523, 0.96989318, 0.90180581, 0.87751163,\n","       0.98751621, 0.85792856, 0.92201676, 0.96944776, 0.99296902,\n","       0.96643807, 0.99723555, 0.98597881, 0.97225099, 0.97574896,\n","       0.99647068, 0.900226  , 0.8478717 , 0.99009761, 0.92253865,\n","       0.82157648, 0.99552051, 0.98605319, 0.98373567, 0.98493364,\n","       0.96455245, 0.48077521, 0.8478717 , 0.98873412, 0.39887046,\n","       0.27788928, 0.93230422, 0.98013207, 0.98618238, 0.95257196,\n","       0.92885213, 0.99509593, 0.93162425, 0.90193125, 0.96391581,\n","       0.84080579, 0.99003221, 0.86398513, 0.99050579, 0.96721743,\n","       0.78117987, 0.99018976, 0.92149049, 0.97110253, 0.8478717 ,\n","       0.96506532, 0.99880089, 0.91506593, 0.89363687, 0.99922088,\n","       0.98951605, 0.99859615, 0.96126161, 0.98935553, 0.97185432,\n","       0.93933011, 0.99187755, 0.98304201, 0.91285155, 0.12615012,\n","       0.99272984, 0.96181994, 0.99538831, 0.99643605, 0.80692047,\n","       0.84349597, 0.99963979, 0.8478717 , 0.90146768, 0.99448438,\n","       0.97936381, 0.98628736, 0.94933873, 0.90123326, 0.98288913,\n","       0.9960067 , 0.97714844, 0.87846262, 0.45174532, 0.98940579,\n","       0.99112264, 0.44341306, 0.99698619, 0.98042515, 0.96542597,\n","       0.94659763, 0.98540733, 0.96034327, 0.05554717, 0.96839983,\n","       0.98317536, 0.93275516, 0.70030166, 0.91418176, 0.90049105,\n","       0.97936463, 0.76334449, 0.96828075, 0.92206306, 0.76234992,\n","       0.84134712, 0.99180181, 0.98009227, 0.97933561, 0.99521613,\n","       0.94250273, 0.98653699, 0.12480295, 0.92774115, 0.99714948,\n","       0.99466258, 0.89657059, 0.60615623, 0.98580738, 0.95707165,\n","       0.97498752, 0.99604508, 0.97965152, 0.96639972, 0.07848293,\n","       0.99325494, 0.9803252 , 0.99642177, 0.99717471])"]},"metadata":{"tags":[]},"execution_count":96}]},{"metadata":{"id":"7Y_mBrvmzMrP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"addb9c11-0196-4499-f70f-cf541f2139b2","executionInfo":{"status":"ok","timestamp":1552828766521,"user_tz":-330,"elapsed":1025,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# calculate accuracy of class predictions\n","from sklearn import metrics\n","metrics.accuracy_score(y_test, y_pred_class)\n","# calculate accuracy\n","metrics.accuracy_score(y_test, y_pred_class)"],"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8763693270735524"]},"metadata":{"tags":[]},"execution_count":98}]},{"metadata":{"id":"sw-0B33tH0Ox","colab_type":"text"},"cell_type":"markdown","source":["## 22. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"]},{"metadata":{"id":"okCTOs1TH0Oy","colab_type":"code","colab":{}},"cell_type":"code","source":["def tokenize_predict(vect):\n","    x_train_dtm = vect.fit_transform(x_train)\n","    print('Features: ', x_train_dtm.shape[1])\n","    x_test_dtm = vect.transform(x_test)\n","    nb = MultinomialNB()\n","    nb.fit(x_train_dtm, y_train)\n","    y_pred_class = nb.predict(x_test_dtm)\n","    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JxZ8jfPEH0O0","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"kdCyAN_IH0O0","colab_type":"code","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"axepytmgH0O4","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"HToGkq7vH0O4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"241d9905-be9f-47dc-9e2c-c35daca3c207","executionInfo":{"status":"ok","timestamp":1552829149448,"user_tz":-330,"elapsed":948,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# use default options for CountVectorizer\n","#vect = CountVectorizer()\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.naive_bayes import MultinomialNB\n","vect = CountVectorizer(ngram_range=(1,2),stop_words='english')\n","\n","# create document-term matrices\n","X_train_dtm = vect.fit_transform(X_train)\n","X_test_dtm = vect.transform(X_test)\n","\n","# use Naive Bayes to predict the star rating\n","nb = MultinomialNB()\n","nb.fit(X_train_dtm, y_train)\n","y_pred_class = nb.predict(X_test_dtm)\n","\n","# calculate accuracy\n","print (accuracy_score(y_test, y_pred_class))"],"execution_count":100,"outputs":[{"output_type":"stream","text":["0.8685446009389671\n"],"name":"stdout"}]},{"metadata":{"id":"iOIlJRxoH0O7","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"6fUhff-oH0O8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"01f08076-8d84-4c16-917d-ef04c2d6109e","executionInfo":{"status":"ok","timestamp":1552829192264,"user_tz":-330,"elapsed":1002,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# use default options for CountVectorizer\n","#vect = CountVectorizer()\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.naive_bayes import MultinomialNB\n","vect = CountVectorizer(ngram_range=(1,2),stop_words='english',max_features=300)\n","\n","# create document-term matrices\n","X_train_dtm = vect.fit_transform(X_train)\n","X_test_dtm = vect.transform(X_test)\n","\n","# use Naive Bayes to predict the star rating\n","nb = MultinomialNB()\n","nb.fit(X_train_dtm, y_train)\n","y_pred_class = nb.predict(X_test_dtm)\n","\n","# calculate accuracy\n","print (accuracy_score(y_test, y_pred_class))"],"execution_count":101,"outputs":[{"output_type":"stream","text":["0.8028169014084507\n"],"name":"stdout"}]},{"metadata":{"id":"S2KZNWVkH0PA","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"3v9XD082H0PB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5390c387-364d-43fa-d9c9-00a30c2a5b7b","executionInfo":{"status":"ok","timestamp":1552829211661,"user_tz":-330,"elapsed":937,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# use default options for CountVectorizer\n","#vect = CountVectorizer()\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.naive_bayes import MultinomialNB\n","vect = CountVectorizer(ngram_range=(1,2),stop_words='english',max_features=15000)\n","\n","# create document-term matrices\n","X_train_dtm = vect.fit_transform(X_train)\n","X_test_dtm = vect.transform(X_test)\n","\n","# use Naive Bayes to predict the star rating\n","nb = MultinomialNB()\n","nb.fit(X_train_dtm, y_train)\n","y_pred_class = nb.predict(X_test_dtm)\n","\n","# calculate accuracy\n","print (accuracy_score(y_test, y_pred_class))"],"execution_count":102,"outputs":[{"output_type":"stream","text":["0.8685446009389671\n"],"name":"stdout"}]},{"metadata":{"id":"We3JK_SRH0PO","colab_type":"text"},"cell_type":"markdown","source":["### Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"]},{"metadata":{"id":"fUHrfDCyH0PP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b52f4918-2c44-4f4c-c0be-f47b591f386b","executionInfo":{"status":"ok","timestamp":1552829242518,"user_tz":-330,"elapsed":1035,"user":{"displayName":"sairam janakiraman","photoUrl":"","userId":"11677302178638953515"}}},"cell_type":"code","source":["# use default options for CountVectorizer\n","#vect = CountVectorizer()\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.naive_bayes import MultinomialNB\n","vect = CountVectorizer(ngram_range=(1,2),min_df=2)\n","\n","# create document-term matrices\n","X_train_dtm = vect.fit_transform(X_train)\n","X_test_dtm = vect.transform(X_test)\n","\n","# use Naive Bayes to predict the star rating\n","nb = MultinomialNB()\n","nb.fit(X_train_dtm, y_train)\n","y_pred_class = nb.predict(X_test_dtm)\n","\n","# calculate accuracy\n","print (accuracy_score(y_test, y_pred_class))"],"execution_count":103,"outputs":[{"output_type":"stream","text":["0.8591549295774648\n"],"name":"stdout"}]},{"metadata":{"id":"3H4k_lVZH0PS","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}